# -*- coding: utf-8 -*-
"""harsh-vardhan-singh-rathore-eda-submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/Hrms1995/a995389de15ae5832aafba2d1df13dd3/harsh-vardhan-singh-rathore-eda-submission.ipynb

# **Project Name**    -Playstore_analysis

`

##### **Project Type**    - EDA
##### **Contribution**    - Individual
##### **Team Member 1 -** Harsh Vardhan Singh Rathore

# **Project Summary -**

Write the summary here within 500-600 words ?

The Google Play Store is a vast marketplace for mobile apps, with over 3 million apps available for download. With so many options to choose from, it can be difficult to find the right apps to be developed. That's where data analysis comes in.
By analyzing data from the Play Store, we can gain insights into which apps are the most popular, which categories are the most in-demand, and which features users are looking for.This information can then be used to make informed decisions about developing the app in particular category.

In this project, we will conduct an exploratory data analysis (EDA) of the Google Play Store dataset. We will explore the data to gain insights into the following aspects:

* The most popular apps
* The most in-demand categories
* The features that users are looking for
* The relationship between app ratings and downloads
* The relationship between app price and downloads

We will use Python and the Pandas library to perform our analysis. We will also use the matplotlib library to create visualizations of our data.

The results of our analysis will be presented in a report. The report will include a summary of our findings, as well as recommendations for how to use the data to make informed decisions about which apps to be developed in which category.

We hope that this project will help you to better understand the Google Play Store and make more informed decisions about which apps to develop in which category.

# **GitHub Link -**

Provide your GitHub Link here.

# **Problem Statement**

# **General Guidelines** : -

1.   Well-structured, formatted, and commented code is required.
2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.
     
     The additional credits will have advantages over other students during Star Student selection.
       
             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go
                       without a single error logged. ]

3.   Each and every logic should have proper comments.
4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.
        

```
# Chart visualization code
```
            

*   Why did you pick the specific chart?
*   What is/are the insight(s) found from the chart?
* Will the gained insights help creating a positive business impact?
Are there any insights that lead to negative growth? Justify with specific reason.

5. You have to create at least 20 logical & meaningful charts having important insights.


[ Hints : - Do the Vizualization in  a structured way while following "UBM" Rule.

U - Univariate Analysis,

B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)

M - Multivariate Analysis
 ]

# ***Let's Begin !***

## ***1. Know Your Data***

### Import Libraries
"""

# Import Libraries
import pandas  as pd
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive
import seaborn as sns
import matplotlib.pyplot as plt

"""### Dataset Loading"""

# Load Dataset
drive.mount('/content/Play_Store_Data.csv')

df_psd=pd.read_csv('/content/Play_Store_Data.csv/MyDrive/Play Store Data.csv')
User_Review = pd.read_csv('/content/User Reviews.csv')

"""### Dataset First View"""

# Dataset First Look
df_psd

"""### Dataset Information"""

# Dataset Info
df_psd.info()

"""#### Duplicate Values"""

# Dataset Duplicate Value Count
df_psd.duplicated().sum()

"""#### Missing Values/Null Values"""

# Missing Values/Null Values Count
df_psd.isnull().sum()

# Visualizing the missing values
sns.heatmap(df_psd.isnull(),cbar = False)

"""### What did you know about your dataset?

Answer:
1. dataset consist of 10841 rows and 13 columns
2. The data set contain 483 duplicated values
3. the rating data has the highest null values 1474

## ***2. Understanding Your Variables***
"""

# Dataset Columns
df_psd.columns

# Dataset Describe
df_psd.describe()

"""### Check Unique Values for each variable."""

# Check Unique Values for each variable.
df_psd['App'].unique()

df_psd['Category'].unique()

df_psd['Rating'].unique()

df_psd[ 'Reviews'].unique()

df_psd['Size'].unique()

df_psd['Installs'].unique()

df_psd['Type'].unique()

df_psd['Price'].unique()

df_psd['Content Rating'].unique()

df_psd['Genres'].unique()

df_psd['Last Updated'].unique()

df_psd['Current Ver'].unique()

df_psd['Android Ver'].unique()

df_psd["Type"]=df_psd["Type"].replace("0",np.nan)

df_psd["Content Rating"].unique()
df_psd["Content Rating"]=df_psd["Content Rating"].replace('Unrated',np.nan)
df_psd["Content Rating"].unique()

df_psd['Genres'].apply(lambda x:x.replace(";","&")if ";"in str(x) else x)
df_psd['Genres']=df_psd.Genres.replace('February 11, 2018',np.nan)
df_psd['Genres'].unique()

df_psd.drop(10472)

df_psd['Rating'].unique()
df_psd['Rating']=df_psd['Rating'].apply(lambda x: float(x))

df_psd.drop_duplicates(inplace=True)

df_psd.dropna(subset=['App','Category','Installs','Type','Content Rating','Genres','Current Ver','Android Ver'], axis=0, inplace=True)
df_psd.info()

df_psd.isnull().sum().sort_values(ascending=False)

(df_psd.isnull().sum()/len(df_psd)*100).sort_values(ascending=False)

"""## 3. ***Data Wrangling***

### Data Wrangling Code
"""

# Write your code to make your dataset analysis ready.
def convert_size(size):
  if isinstance(size,str):
    if 'k' in size:
      return float(size.replace('k'," "))*1024
    elif 'M' in size:
      return float(size.replace('M'," "))*1024*1024
    elif 'Varies with device' in size:
      return np.nan
  return size

df_psd['Size']=df_psd['Size'].apply(convert_size)
df_psd['Size'] = df_psd['Size'].replace("1,000+",'1000')
df_psd['Size']= df_psd['Size'].apply(lambda x:float(x))
df_psd['Size in MB']= df_psd['Size'].apply(lambda x:x/(1024*1024))

df_psd['Price']=df_psd['Price'].apply(lambda x: x.replace("$"," ")  if "$" in str(x) else(x))
df_psd['Price']=df_psd['Price'].apply(lambda x: x.replace('Everyone','0') if 'Everyone' in str(x) else(x))
df_psd['Price']=df_psd['Price'].apply(lambda x: float(x))
df_psd['Price'].dtype

df_psd['Installs'].unique()

df_psd['Installs']= df_psd['Installs'].apply(lambda x:x.replace(",","")if "," in str(x) else(x))
df_psd['Installs']= df_psd['Installs'].apply(lambda x:x.replace("+"," ")if "+" in str(x) else(x))
df_psd['Installs']=df_psd.Installs.replace("Free",np.nan)
df_psd['Installs']=df_psd['Installs'].astype(float)
df_psd['Installs'].dtype

df_psd['Rating'].mean().round(2)

df_psd['Rating'] = df_psd['Rating'].fillna(4.2)

df_psd['Reviews']=df_psd['Reviews'].astype(float)
df_psd["Type"]=df_psd["Type"].replace("0",np.nan)

df_psd.describe()

df_psd.isnull().sum()

"""### What all manipulations have you done and insights you found?

Answer
      1. I found data was massy and contains lot of error and Size of application was further transformed to MB where new column was framed in form of Size in MB
      2. Rating mean was calculated that is 4.2 where null values was replaced with 4.2 rating

## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***

Q1.Which Category has Highest Number of Reviews?
"""

# Chart - 1 visualization code
z=df_psd.groupby('Category')['Reviews'].agg(np.sum)
Sorted_data=z.sort_values(ascending=False,inplace=True)
z.plot(kind='bar',figsize=(10,8))
plt.xticks(rotation=90)
plt.ylabel('Review',color='Blue')
plt.xlabel('Category',color='Blue')
plt.title('Category vs Reviews',color='blue')

"""##### 1. Why did you pick the specific chart?

Answer - Bar Chart was chosen beacause it contain various categorical data

##### 2. What is/are the insight(s) found from the chart?

Answer. From Graph I found that the Game,Communication, Social, Family,Tools are tp five Category with highest review.

##### 3. Will the gained insights help creating a positive business impact?
Are there any insights that lead to negative growth? Justify with specific reason.

Answer- It is found that the Highest review caegory will help the developer in understanding the top five category to build a application

#### Chart - 2
"""

# Chart - 2 visualization code
z=df_psd.groupby('Category')['Rating'].agg(np.mean).sort_values(ascending=False).head(5)
z.plot(kind='bar')
plt.xticks(rotation=90)
plt.ylabel('Rating',color='Blue')
plt.xlabel('Category',color='Blue')
plt.title('Category vs Rating',color='blue')

"""##### 1. Why did you pick the specific chart?

*Answer Bar chart are mostly used for the categorical data here there are different categories are available.

##### 2. What is/are the insight(s) found from the chart?

Answer Here, I found that Education , ART_and_ design, Event, Book and references,Personalisation are the top 5 category which poses highest rating.

##### 3. Will the gained insights help creating a positive business impact?
Are there any insights that lead to negative growth? Justify with specific reason.

*Answer* The data can help developer to know the highest rating app category liked by people so that developer can develop the app in this category

---

#### Chart - 3
"""

# Chart - 3 visualization code
z=df_psd.groupby('Category')['Installs'].agg(np.sum).sort_values(ascending=False)
z.plot(kind='bar')
plt.xlabel('Category',color= 'Blue')
plt.ylabel('Installs',color= 'Blue')
plt.title('Category vs Installs',color= 'Blue')

"""##### 1. Why did you pick the specific chart?

Answer Here. Bar Cart is best suitable for the categorical data representation

##### 2. What is/are the insight(s) found from the chart?

Answer Here from this chart I found that the  Game, communication, social,productivity and tools are the highest install category.

##### 3. Will the gained insights help creating a positive business impact?
Are there any insights that lead to negative growth? Justify with specific reason.

Answer  It will help developer in developing the app in top category.

#### Chart - 4
"""

# Chart - 4 visualization code
pie=df_psd['Type'].value_counts()
y=[9582,762]
z=['Free','Paid']
myexplode = [0,0.2]
plt.pie(y,labels=z,explode=myexplode,autopct='%1.1f%%')

plt.legend()
plt.show()

"""##### 1. Why did you pick the specific chart?

Answer Here I chosed the pie Chart which is best suitable for proportion.

##### 2. What is/are the insight(s) found from the chart?

Answer Here I found that the 92.6% are free app and 7.4% is only paid app

##### 3. Will the gained insights help creating a positive business impact?
Are there any insights that lead to negative growth? Justify with specific reason.

Answer Here It will help the developer to know that after developing that I should put the app in the free and paid

#### Chart - 5
"""

# Chart - 5 visualization code
x=[]
y=[]
z=dict(df_psd['Content Rating'].value_counts())
for key, value in z.items():
  x.append(key)
  y.append(value)
  plt.bar(x,y)
  plt.xticks(rotation = 45)
  plt.ylabel('Content Rating')

"""##### 1. Why did you pick the specific chart?

Answer Here. Bar chart is best suitable for representing the categorical Data

##### 2. What is/are the insight(s) found from the chart?

Answer Here, It is found that the app that are made downloading for everyone has the highest download

##### 3. Will the gained insights help creating a positive business impact?
Are there any insights that lead to negative growth? Justify with specific reason.

Answer Here: It will help the developer to develop the app by keeping everyone in mind.

#### Chart - 6
"""

# top 20 app with highest number of install
df_psd.groupby('App')['Installs'].max().sort_values(ascending=False).head(20)

"""#### Chart - 7"""

# Chart - 7 visualization code
plt.figure(figsize=(15,10))
num_col= ['Rating','Reviews','Installs','Price','Size','Size in MB']
sns.heatmap(df_psd[num_col].corr(),annot=True)

"""##### 1. Why did you pick the specific chart?

Answer Here. for showing correlation among different column this heatmap plot is best suitable

##### 2. What is/are the insight(s) found from the chart?

Answer Here
1. after plot,come to know that there is relation between Reviews and Installs.

Answer Here

#### Chart - 8
"""

# Chart - 8 visualization code

sns.pairplot(df_psd)

"""#### Chart - 9"""

plt.figure(figsize=(8,6))
sns.scatterplot(x='Price',y='Installs',data=df_psd)

"""##### 1. Why did you pick the specific chart?

Answer Here.

##### 2. What is/are the insight(s) found from the chart?

Answer Here It is found from the chart that the data has highest install in price range between 0 to 100 beacuse it have the dense region in between that region only

##### 3. Will the gained insights help creating a positive business impact?
Are there any insights that lead to negative growth? Justify with specific reason.

Answer- If developer is trying to develop app and want to develop paid app can put price of app in between 0 to 100

#### Chart - 10
"""

# Chart - 10 visualization code
z= df_psd.groupby('Size in MB')['Installs'].sum().sort_values(ascending = False).head(10)
z.plot(kind='bar')
plt.ylabel('Installs')

"""Developer Should keep the range of the app size between 76 to 67 Mb for having max installs"""

# sum all the category
x=[]
y=[]
z=df_psd['Category'].value_counts().sort_values(ascending = False).head(10)
for key, value in z.items():
  x.append(key)
  y.append(value)

plt.pie(y,labels=x,autopct='%1.1f%%')

# Most popular paid app

df_paid = df_psd[df_psd['Type'] == 'Paid']
z=df_paid['App'].value_counts().sort_values(ascending=False).head(10)
z.plot(kind = 'bar')
plt.xlabel('Top_Paid_App')
plt.ylabel('Values')

"""



Here, I have choosen bar chart which is best for categorical presentation.
I have plotted a graph to know the Top paid App. Minecraft, camera fv5,The Game of life etc are top paid app downloaded from playstore."""

df_paid = df_psd[df_psd['Type'] == 'Free']
z=df_paid['App'].value_counts().sort_values(ascending=False).head(10)
z.plot(kind = 'bar')
plt.xlabel('Top_Free_App')
plt.ylabel('Values')

"""Here I Have choose bar chart which is best for categorical presentation.
I have plotted a graph to know the Top Free App, Roblox, 8 Ball Pool,BubbleShooter etc are top free app downloaded from playstore.
"""

#Review Analysis
merged_df = pd.merge(df_psd,User_Review, on ='App', how = "inner")
merged_df = merged_df.dropna(subset=['Sentiment', 'Translated_Review'])
sns.set_style('ticks')
fig, ax = plt.subplots()
fig.set_size_inches(11, 8)
ax = sns.boxplot(x =merged_df['Type'], y =merged_df['Sentiment_Polarity'])
ax.set_title('Sentiment Polarity Distribution')

"""The box plot shows the distribution of sentiment polarity for free and paid apps. The median sentiment polarity for free apps is 0.35, while the median sentiment polarity for paid apps is 0.45. This suggests that users are generally more positive about free apps than paid apps. However, it is important to note that there is a lot of variation in sentiment polarity for both free and paid apps.

# **Conclusion**

1.The “Family” category emerges as the most popular, followed by “Game” and “Tools,” indicating prevalent genres among apps. Noteworthy apps in the “Family” category include Google Play Games and Minecraft. The “Game” and “Communication” categories drive the highest number of installations.
2.A strong positive correlation is observed between reviews and installations.
3.If developer is trying to develop a app and want to put in paid region, can put price range in between 0 to 100.
4.Content rating should be made everyone.
5.Free App has the Highest number of downloads.
6.Mine craft and Camera FV5 are the top paid app.
7.Roblox and 8ball pool are top free app.

The findings can serve as a valuable guide for app developers and marketers to strategize their app design, development, and pricing.
"""